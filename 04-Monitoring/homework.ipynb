{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8fa97978-b7ca-49b4-ada8-5d896d8b31ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d45ce1b8-0536-43a8-894d-7083e077e81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "github_url=\"https://github.com/DataTalksClub/llm-zoomcamp/blob/main/04-monitoring/data/results-gpt4o-mini.csv\"\n",
    "url = f'{github_url}?raw=1'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d4ca559-cd54-4744-b6c3-e4082c63386f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b1afeaa-9eca-4017-9fde-d5fdcd72ddec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.iloc[:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0cd89691-e283-4c0a-b141-118db6c7d2ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.10.13/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "You try to use a model that was created with version 3.0.0.dev0, however, your version is 2.7.0. This might cause unexpected behavior or errors. In that case, try to update to the latest version.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model_name=\"multi-qa-mpnet-base-dot-v1\"\n",
    "embedding_model = SentenceTransformer(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0f8904-f31a-48ff-b0aa-1fdc815cfefd",
   "metadata": {},
   "source": [
    "## Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf59b0c4-df3e-4db1-8900-a6f2969f4501",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_llm = df.iloc[0].answer_llm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ded67f7-e798-4e97-828a-c192e422991c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.42244655"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_vector = embedding_model.encode(answer_llm)\n",
    "embedding_vector[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab0b954-34b5-459d-b7e4-51cfbe4a5d68",
   "metadata": {},
   "source": [
    "## Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cca50bb5-1e96-46df-81ec-2a47f842bc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_similarity(record):\n",
    "    answer_orig = record['answer_orig']\n",
    "    answer_llm = record['answer_llm']\n",
    "    \n",
    "    v_llm = embedding_model.encode(answer_llm)\n",
    "    v_orig = embedding_model.encode(answer_orig)\n",
    "    \n",
    "    return v_llm.dot(v_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d4a1d152-37e5-4026-9298-40777af33af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_gpt4omini= df.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0e2749e3-10c0-4dae-9574-6921b4a12740",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [02:21<00:00,  2.12it/s]\n"
     ]
    }
   ],
   "source": [
    "evaluations = []\n",
    "\n",
    "for record in tqdm(results_gpt4omini):\n",
    "    sim = compute_similarity(record)\n",
    "    evaluations.append(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b7009433-4f49-4ab5-93a0-934cf23af2b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    300.000000\n",
       "mean      27.495996\n",
       "std        6.384742\n",
       "min        4.547924\n",
       "25%       24.307844\n",
       "50%       28.336870\n",
       "75%       31.674309\n",
       "max       39.476013\n",
       "Name: cosine, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['cosine'] = evaluations\n",
    "df['cosine'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07ee910-5324-43d8-b3ea-a168ec09029a",
   "metadata": {},
   "source": [
    "## Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "559b7e70-0291-4fcb-8243-d4f54affcd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(v):\n",
    "    norm = np.sqrt((v * v).sum())\n",
    "    v_norm = v / norm\n",
    "    return v_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9470d5c0-da0b-4480-9b78-f732a23f3dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_similarity_normalized(record):\n",
    "    answer_orig = record['answer_orig']\n",
    "    answer_llm = record['answer_llm']\n",
    "    \n",
    "    v_llm = embedding_model.encode(answer_llm)\n",
    "    v_orig = embedding_model.encode(answer_orig)\n",
    "\n",
    "    normalized_v_llm = normalize(v_llm)\n",
    "    normalized_v_orig = normalize(v_orig)\n",
    "    \n",
    "    return normalized_v_llm.dot(normalized_v_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cbd4788b-2357-4715-b89a-1577032ae1e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [02:19<00:00,  2.15it/s]\n"
     ]
    }
   ],
   "source": [
    "evaluations_norm = []\n",
    "\n",
    "for record in tqdm(results_gpt4omini):\n",
    "    sim = compute_similarity_normalized(record)\n",
    "    evaluations_norm.append(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bcd55e4c-5c1d-4527-90d3-56d6a24e9506",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    300.000000\n",
       "mean       0.728393\n",
       "std        0.157755\n",
       "min        0.125357\n",
       "25%        0.651273\n",
       "50%        0.763761\n",
       "75%        0.836235\n",
       "max        0.958796\n",
       "Name: cosine_norm, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['cosine_norm'] = evaluations_norm\n",
    "df['cosine_norm'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5440ec0d-1cd9-4217-ad9f-2f3ff669844f",
   "metadata": {},
   "source": [
    "## Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a0dfa1c0-bf1c-4235-8dc3-78c5b833bf73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rouge\n",
      "  Downloading rouge-1.0.1-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: six in /home/codespace/.local/lib/python3.10/site-packages (from rouge) (1.16.0)\n",
      "Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
      "Installing collected packages: rouge\n",
      "Successfully installed rouge-1.0.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "92ea138b-2f66-49eb-a204-75bb69437b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: rouge [-h] [-f] [-a] [--ignore_empty]\n",
      "             [--metrics {1,2,3,4,5,L} [{1,2,3,4,5,L} ...]]\n",
      "             [--stats {R,P,F} [{R,P,F} ...]]\n",
      "             hypothesis reference\n",
      "rouge: error: the following arguments are required: hypothesis, reference\n"
     ]
    }
   ],
   "source": [
    "!rouge --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8aaba2fe-01bc-4a20-8d80-3b0ddc2fac3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge import Rouge\n",
    "rouge_scorer = Rouge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "38234ad3-13f8-4e15-ab05-de56b86f39a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "answer_llm     Yes, all sessions are recorded, so if you miss...\n",
       "answer_orig    Everything is recorded, so you won’t miss anyt...\n",
       "document                                                5170565b\n",
       "question                    Are sessions recorded if I miss one?\n",
       "course                                 machine-learning-zoomcamp\n",
       "cosine                                                 32.344711\n",
       "cosine_norm                                             0.777956\n",
       "Name: 10, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r= df.iloc[10]\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "92993c2b-ea39-426e-8af6-3e94f1e5344e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = rouge_scorer.get_scores(r['answer_llm'], r['answer_orig'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9c06e39f-c2e7-43f7-9550-39fe15544962",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge-1': {'r': 0.45454545454545453,\n",
       "  'p': 0.45454545454545453,\n",
       "  'f': 0.45454544954545456},\n",
       " 'rouge-2': {'r': 0.21621621621621623,\n",
       "  'p': 0.21621621621621623,\n",
       "  'f': 0.21621621121621637},\n",
       " 'rouge-l': {'r': 0.3939393939393939,\n",
       "  'p': 0.3939393939393939,\n",
       "  'f': 0.393939388939394}}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b43d8d-2654-4883-9fe8-1698ef8a1ef3",
   "metadata": {},
   "source": [
    "## Q5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1ae2b692-0363-4ae3-8a32-203b3e59c155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average of 'f' values: 0.35490034990035496\n"
     ]
    }
   ],
   "source": [
    "# Extract the 'f' values\n",
    "f_values = [v['f'] for v in scores.values()]\n",
    "\n",
    "# Compute the average\n",
    "average_f = sum(f_values) / len(f_values)\n",
    "\n",
    "print(\"Average of 'f' values:\", average_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f275239-7377-4bcf-8e17-e90ca9ab9413",
   "metadata": {},
   "source": [
    "## Q6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "02ad089b-27d1-4299-9992-379b40598d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge_scores_list = []\n",
    "\n",
    "for index, r in df.iterrows():\n",
    "    scores = rouge_scorer.get_scores(r['answer_llm'], r['answer_orig'])[0]\n",
    "    rouge_scores_list.append(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6efcbd68-86cd-4e25-a320-f6ba36410339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     rouge-1_f  rouge-2_f  rouge-l_f\n",
      "0     0.095238   0.028169   0.095238\n",
      "1     0.125000   0.055556   0.093750\n",
      "2     0.415584   0.177778   0.389610\n",
      "3     0.216216   0.047059   0.189189\n",
      "4     0.142076   0.033898   0.120219\n",
      "..         ...        ...        ...\n",
      "295   0.654545   0.540984   0.618182\n",
      "296   0.590164   0.460432   0.557377\n",
      "297   0.654867   0.564516   0.637168\n",
      "298   0.304762   0.132231   0.304762\n",
      "299   0.179487   0.023529   0.153846\n",
      "\n",
      "[300 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Extract the 'f' values and create a list of dictionaries\n",
    "records = []\n",
    "for rouge_scores in rouge_scores_list:\n",
    "    record = {\n",
    "        'rouge-1_f': rouge_scores['rouge-1']['f'],\n",
    "        'rouge-2_f': rouge_scores['rouge-2']['f'],\n",
    "        'rouge-l_f': rouge_scores['rouge-l']['f']\n",
    "    }\n",
    "    records.append(record)\n",
    "\n",
    "# Create a DataFrame\n",
    "df_rouge_scores = pd.DataFrame(records)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df_rouge_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e8146962-59fa-4239-a811-b7f80ee8ef22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20696501983423318"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rouge_scores['rouge-2_f'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96166d0-8674-4f5d-952e-5d9b34672af6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
