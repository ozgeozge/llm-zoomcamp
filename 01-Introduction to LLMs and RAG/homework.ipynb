{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d92ccb8-40f9-491a-8fc6-158eb484730e",
   "metadata": {},
   "source": [
    "# Q1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c071538d-7843-465e-8fcc-3490a771d521",
   "metadata": {},
   "source": [
    "```\n",
    "curl localhost:9200\n",
    "```\n",
    "\n",
    "{\n",
    "  \"name\" : \"\",\n",
    "  \"cluster_name\" : \"\",\n",
    "  \"cluster_uuid\" : \"\",\n",
    "  \"version\" : {\n",
    "    \"number\" : \"8.4.3\",\n",
    "    \"build_flavor\" : \"default\",\n",
    "    \"build_type\" : \"docker\",\n",
    "    \"build_hash\" : \"\",\n",
    "    \"build_date\" : \"\",\n",
    "    \"build_snapshot\" : false,\n",
    "    \"lucene_version\" : \"9.3.0\",\n",
    "    \"minimum_wire_compatibility_version\" : \"0\",\n",
    "    \"minimum_index_compatibility_version\" : \"0\"\n",
    "  },"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8fa734-6ff1-4996-a600-1cea0bacc6c7",
   "metadata": {},
   "source": [
    "# Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ada552d8-a348-4e34-abe0-67e55cbe6534",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "\n",
    "docs_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main/01-intro/documents.json?raw=1'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents_raw = docs_response.json()\n",
    "\n",
    "documents = []\n",
    "\n",
    "for course in documents_raw:\n",
    "    course_name = course['course']\n",
    "\n",
    "    for doc in course['documents']:\n",
    "        doc['course'] = course_name\n",
    "        documents.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "604c29b5-ff1f-4d80-bc9a-adde2ac0edf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'course-questionss'})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "es_client = Elasticsearch('http://localhost:9200') \n",
    "index_settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"text\": {\"type\": \"text\"},\n",
    "            \"section\": {\"type\": \"text\"},\n",
    "            \"question\": {\"type\": \"text\"},\n",
    "            \"course\": {\"type\": \"keyword\"} \n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "index_name = \"course-questionss\"\n",
    "\n",
    "es_client.indices.create(index=index_name, body=index_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "089b7697-e20a-496f-a98a-b0cedebe9b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in documents:\n",
    "    es_client.index(index=index_name, document=doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65a5429-1a78-4d32-8d01-c5ae7ac64ea7",
   "metadata": {},
   "source": [
    "# Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "87aa60c7-8197-44f2-bf7c-b352b85b7995",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'How do I execute a command in a running docker container?'\n",
    "\n",
    "def elastic_search(query):\n",
    "    search_query = {\n",
    "        \"size\": 5,\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"must\": {\n",
    "                    \"multi_match\": {\n",
    "                        \"query\": query,\n",
    "                        \"fields\": [\"question^4\", \"text\"],\n",
    "                        \"type\": \"best_fields\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    response = es_client.search(index=index_name, body=search_query)\n",
    "    \n",
    "    result_docs = []\n",
    "    result_scores = []\n",
    "    for hit in response['hits']['hits']:\n",
    "        result_docs.append(hit['_source'])\n",
    "        result_scores.append(hit['_score'])\n",
    "    \n",
    "    return (result_docs, result_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ac942519-86df-43f4-ae9f-242c7155edc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_result= elastic_search(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "21bf2b1f-9a21-41ea-b9f4-5ed353afaf08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([{'text': 'Launch the container image in interactive mode and overriding the entrypoint, so that it starts a bash command.\\ndocker run -it --entrypoint bash <image>\\nIf the container is already running, execute a command in the specific container:\\ndocker ps (find the container-id)\\ndocker exec -it <container-id> bash\\n(Marcos MJD)',\n",
       "   'section': '5. Deploying Machine Learning Models',\n",
       "   'question': 'How do I debug a docker container?',\n",
       "   'course': 'machine-learning-zoomcamp'},\n",
       "  {'text': 'Launch the container image in interactive mode and overriding the entrypoint, so that it starts a bash command.\\ndocker run -it --entrypoint bash <image>\\nIf the container is already running, execute a command in the specific container:\\ndocker ps (find the container-id)\\ndocker exec -it <container-id> bash\\n(Marcos MJD)',\n",
       "   'section': '5. Deploying Machine Learning Models',\n",
       "   'question': 'How do I debug a docker container?',\n",
       "   'course': 'machine-learning-zoomcamp'},\n",
       "  {'text': 'In case running pgcli  locally causes issues or you do not want to install it locally you can use it running in a Docker container instead.\\nBelow the usage with values used in the videos of the course for:\\nnetwork name (docker network)\\npostgres related variables for pgcli\\nHostname\\nUsername\\nPort\\nDatabase name\\n$ docker run -it --rm --network pg-network ai2ys/dockerized-pgcli:4.0.1\\n175dd47cda07:/# pgcli -h pg-database -U root -p 5432 -d ny_taxi\\nPassword for root:\\nServer: PostgreSQL 16.1 (Debian 16.1-1.pgdg120+1)\\nVersion: 4.0.1\\nHome: http://pgcli.com\\nroot@pg-database:ny_taxi> \\\\dt\\n+--------+------------------+-------+-------+\\n| Schema | Name             | Type  | Owner |\\n|--------+------------------+-------+-------|\\n| public | yellow_taxi_data | table | root  |\\n+--------+------------------+-------+-------+\\nSELECT 1\\nTime: 0.009s\\nroot@pg-database:ny_taxi>',\n",
       "   'section': 'Module 1: Docker and Terraform',\n",
       "   'question': 'PGCLI - running in a Docker container',\n",
       "   'course': 'data-engineering-zoomcamp'},\n",
       "  {'text': 'In case running pgcli  locally causes issues or you do not want to install it locally you can use it running in a Docker container instead.\\nBelow the usage with values used in the videos of the course for:\\nnetwork name (docker network)\\npostgres related variables for pgcli\\nHostname\\nUsername\\nPort\\nDatabase name\\n$ docker run -it --rm --network pg-network ai2ys/dockerized-pgcli:4.0.1\\n175dd47cda07:/# pgcli -h pg-database -U root -p 5432 -d ny_taxi\\nPassword for root:\\nServer: PostgreSQL 16.1 (Debian 16.1-1.pgdg120+1)\\nVersion: 4.0.1\\nHome: http://pgcli.com\\nroot@pg-database:ny_taxi> \\\\dt\\n+--------+------------------+-------+-------+\\n| Schema | Name             | Type  | Owner |\\n|--------+------------------+-------+-------|\\n| public | yellow_taxi_data | table | root  |\\n+--------+------------------+-------+-------+\\nSELECT 1\\nTime: 0.009s\\nroot@pg-database:ny_taxi>',\n",
       "   'section': 'Module 1: Docker and Terraform',\n",
       "   'question': 'PGCLI - running in a Docker container',\n",
       "   'course': 'data-engineering-zoomcamp'},\n",
       "  {'text': 'If you are trying to run Flask gunicorn & MLFlow server from the same container, defining both in Dockerfile with CMD will only run MLFlow & not Flask.\\nSolution: Create separate shell script with server run commands, for eg:\\n> \\tscript1.sh\\n#!/bin/bash\\ngunicorn --bind=0.0.0.0:9696 predict:app\\nAnother script with e.g. MLFlow server:\\n>\\tscript2.sh\\n#!/bin/bash\\nmlflow server -h 0.0.0.0 -p 5000 --backend-store-uri=sqlite:///mlflow.db --default-artifact-root=g3://zc-bucket/mlruns/\\nCreate a wrapper script to run above 2 scripts:\\n>\\twrapper_script.sh\\n#!/bin/bash\\n# Start the first process\\n./script1.sh &\\n# Start the second process\\n./script2.sh &\\n# Wait for any process to exit\\nwait -n\\n# Exit with status of process that exited first\\nexit $?\\nGive executable permissions to all scripts:\\nchmod +x *.sh\\nNow we can define last line of Dockerfile as:\\n> \\tDockerfile\\nCMD ./wrapper_script.sh\\nDont forget to expose all ports defined by services!',\n",
       "   'section': 'Module 4: Deployment',\n",
       "   'question': 'Running multiple services in a Docker container',\n",
       "   'course': 'mlops-zoomcamp'}],\n",
       " [84.17781, 84.17781, 75.66571, 75.66571, 72.20392])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16819da-b871-48a1-862d-601f6d9744c7",
   "metadata": {},
   "source": [
    "# Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "889a3b24-a2e4-4a0f-a202-c20c18e6963f",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'How do I execute a command in a running docker container?'\n",
    "\n",
    "def elastic_search(query):\n",
    "    search_query = {\n",
    "        \"size\": 3,\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"must\": {\n",
    "                    \"multi_match\": {\n",
    "                        \"query\": query,\n",
    "                        \"fields\": [\"question^4\", \"text\"],\n",
    "                        \"type\": \"best_fields\"\n",
    "                    }\n",
    "                },\n",
    "                \"filter\": {\n",
    "                    \"term\": {\n",
    "                        \"course\": \"machine-learning-zoomcamp\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    response = es_client.search(index=index_name, body=search_query)\n",
    "    \n",
    "    result_docs = []\n",
    "    for hit in response['hits']['hits']:\n",
    "        result_docs.append(hit['_source'])    \n",
    "    return (result_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e52b7fa1-bcd7-4f5d-ad55-e79f800d74f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'Launch the container image in interactive mode and overriding the entrypoint, so that it starts a bash command.\\ndocker run -it --entrypoint bash <image>\\nIf the container is already running, execute a command in the specific container:\\ndocker ps (find the container-id)\\ndocker exec -it <container-id> bash\\n(Marcos MJD)',\n",
       "  'section': '5. Deploying Machine Learning Models',\n",
       "  'question': 'How do I debug a docker container?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'text': 'Launch the container image in interactive mode and overriding the entrypoint, so that it starts a bash command.\\ndocker run -it --entrypoint bash <image>\\nIf the container is already running, execute a command in the specific container:\\ndocker ps (find the container-id)\\ndocker exec -it <container-id> bash\\n(Marcos MJD)',\n",
       "  'section': '5. Deploying Machine Learning Models',\n",
       "  'question': 'How do I debug a docker container?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'text': \"You can copy files from your local machine into a Docker container using the docker cp command. Here's how to do it:\\nTo copy a file or directory from your local machine into a running Docker container, you can use the `docker cp command`. The basic syntax is as follows:\\ndocker cp /path/to/local/file_or_directory container_id:/path/in/container\\nHrithik Kumar Advani\",\n",
       "  'section': '5. Deploying Machine Learning Models',\n",
       "  'question': 'How do I copy files from my local machine to docker container?',\n",
       "  'course': 'machine-learning-zoomcamp'}]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_result= elastic_search(query)\n",
    "search_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f39466e4-1363-4bf7-9482-0b555d2138f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How do I debug a docker container?\n",
      "How do I debug a docker container?\n",
      "How do I copy files from my local machine to docker container?\n"
     ]
    }
   ],
   "source": [
    "for res in search_result:\n",
    "    print(res['question'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1392f1-e407-4778-84e8-26971b473fb3",
   "metadata": {},
   "source": [
    "# Q5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "526d5612-fece-40ed-b6cf-3fbdf42944ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(query, search_results):\n",
    "    prompt_template = \"\"\"\n",
    "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "CONTEXT:\n",
    "{context}\n",
    "\"\"\".strip()\n",
    "\n",
    "    context_template = \"\"\"\n",
    "Q: {question}\n",
    "A: {text}\n",
    "\"\"\".strip()\n",
    "\n",
    "    context = \"\"\n",
    "    \n",
    "    for doc in search_results:\n",
    "        context = context + f\"Q: {doc['question']}\\nA: {doc['text']}\\n\\n\"\n",
    "    \n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "    return prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bd547f66-987a-49de-ab74-dbad1073f595",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = build_prompt(query, search_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0fe821c0-2948-4ab6-9c44-b684172e5a4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1399"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0eaf38b-8132-4706-bb60-97be9b2ab30d",
   "metadata": {},
   "source": [
    "# Q6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3b8d6aad-8f0f-436c-8661-b671cd3ae04e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tiktoken\n",
      "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting regex>=2022.1.18 (from tiktoken)\n",
      "  Downloading regex-2024.5.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests>=2.26.0 in /home/codespace/.local/lib/python3.10/site-packages (from tiktoken) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2024.2.2)\n",
      "Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading regex-2024.5.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (775 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m775.1/775.1 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: regex, tiktoken\n",
      "Successfully installed regex-2024.5.15 tiktoken-0.7.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "eab5654b-b409-40e8-8b55-276e687e8be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3237fd43-d2ac-4da7-97c5-a9bad773e355",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens=encoding.encode(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f7d8b6dc-2c31-477b-8738-7ee9c81f91b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "310"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fd2f2391-259b-4367-92f5-1bf9e82c732c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b\"You're\""
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding.decode_single_token_bytes(63842)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a0cdf0-2d32-4be7-89c4-e7d0036991fa",
   "metadata": {},
   "source": [
    "# Q7 Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bdaedc01-e4c2-4252-a149-d7cead3347fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from groq import Groq\n",
    "\n",
    "# Instantiation of Groq Client\n",
    "client = Groq(\n",
    "    api_key=os.environ.get(\"GROQ_API_KEY\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "68a9e365-a233-40ab-8c22-4ff80fd5b645",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm(prompt):\n",
    "    response = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "           \"role\": \"user\", \"content\": prompt\n",
    "        }\n",
    "    ],\n",
    "    model=\"mixtral-8x7b-32768\",\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b6c4842a-3ab1-43f7-9f0d-9fbda5537b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(query):\n",
    "    search_results = elastic_search(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    answer = llm(prompt)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ffb458f2-94cf-4c18-ad26-4bfd7d018489",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"To execute a command in a running Docker container, you can use the `docker exec` command. Here's how to do it:\\n\\n1. First, find the ID of the running Docker container using the command `docker ps`.\\n2. Then, use the `docker exec` command to run the desired command in the specific container. The basic syntax is as follows:\\n\\ndocker exec -it <container-id> <command>\\n\\nReplace `<container-id>` with your container's ID and `<command>` with the command you want to execute. For example, to start a bash shell in the running container, use:\\n\\ndocker exec -it <container-id> bash\""
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df135525-dfa2-4d23-83b8-8cc883812c7c",
   "metadata": {},
   "source": [
    "# Q8 Optional"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1fc1b6-8b32-413d-a637-73fed06c09af",
   "metadata": {},
   "source": [
    "1000 requests:\n",
    "\n",
    "150000 tokens sent: 1000 tokens $ 0.005 -> 0.005 * 150 = 0.75\n",
    "250000 tokens received: 1000 tokens $ 0.015 -> 0.015 * 250 = 3.75\n",
    "\n",
    "Total: 0.75 + 3.75 = $ 4.5\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
